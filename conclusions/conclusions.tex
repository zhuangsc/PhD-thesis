
\chapter{Conclusions}
\label{chap:conclusions}

In this thesis, we presented two approaches that mitigate the inherent heterogeneity found
even in processors of the same design model, due to manufacturing variability.
Manufacturing variability refers to the variability in power consumption and frequency of
processors because of artifacts during the manufacturing process of transistors, which
result in variations in transistor parameters, like $V_{th}$ and $L_{eff}$.  Our first
approach is implemented at runtime level and redistributes power among socket on NUMA
nodes, to mitigate their performance variability, essentially improving dynamic
load-balancing.  Our second approach is implemented at workload manager level, where we
develop and use a variability-aware power prediction model to guide system-wide scheduling
decisions and improve the system's throughput and energy efficiency.  Furthermore, in
order to evaluate both approaches, we have implemented the PARSECSs benchmark suite, using
a task-based programming model (OpenMP 4.0), based on the original PARSEC benchmarks.  In
this Chapter we present the conclusions and possible future directions this research line
can head to, based on the results and ideas presented in this thesis. 

\section{Relevant Benchmarking in HPC}
Benchmarking is key component for researchers to evaluate their ideas and proposals, both
at software and hardware level.  Choosing the benchmark applications carefully is vital
for an evaluation to be meaningful and not biased. Benchmark applications should ideally
capture all application behaviors and scenarios that can occur when running actual HPC
workloads.  Typically in HPC, small kernel applications are the backbone of every
benchmark suite.  The reasoning behind this choice, is that HPC applications are usually
composed by smaller kernels, which can be efficiently parallelized.  This approach
however, is not representative of many workloads that are run today on HPC systems.  As
HPC computing has become more accessible today and more powerful programming models allow
users to parallelize a more diverse set of applications, these kernels are no longer
representative of the applications or programming paradigms of the workload running on HPC
systems.  In Section \ref{chap:task_based_benchmarks}, we present PARSECSs, a task-based
implementation of the PARSEC benchmark suite.  The PARSECSs benchmark suite is composed by
applications from a large number of different domains, used in todays computing.  Our
implementation use a state-of-the-art task-based model and employ emerging programming
paradigms, such as pipeline parallelism, in addition to traditional ones.  We also
evaluate our task-based implementations to the original PARSEC Pthreads/OpenMP 2.0
versions.  We show that task-parallelism can be applied on varied domains of computing and
that it is actually easier to use.  We show that although in many cases, such as the
smaller kernel applications, task-parallelism is as efficient as traditional models, there
are many occasions where it can improve an applications performance.  The asynchronous
nature of tasks with the addition of dataflow relation, allow the user to easily overlap
I/O phases with computation.  Moreover, the underlying runtime is able to efficiently
synchronize and load-balance parallel applications.  In comparison, the original PARSEC
applications require the user to implement such load-balancing and synchronization
mechanisms from scratch, resulting in more complex and less portable code.  Moreover,
using a benchmark suite which is implemented with a state-of-the-art runtime, allows
researchers to implement their ideas at runtime level, without the need to modify each
application in the suite.

\section{Runtime Mitigation of Manufacturing Variability}
Advanced programming models are typically coupled with dedicated runtime systems, which
deal with synchronization and load-balancing in parallel applications.  These runtimes
offer ideal platforms for developing experimental solutions for any kind of performance
problems parallel applications may face.  Moreover, runtimes can hide architectural
details from the user and allow the user to design applications without considering code
portability across different machines, or particularities of specific hardware.  This
creates an ideal platform for developing a framework capable of dealing with the issues
created by manufacturing variability, since the user can let the runtime deal measure and
deal with variability at execution time, in a transparent manner.

Static solutions are not practical when dealing with manufacturing variability.  First,
processors are not characterized by vendors regarding their power variability.  This power
variability translates also to performance variability, since when power constraining a
processor, it can no longer consume additional power to reach the nominal frequency set by
the manufacturer.  Moreover, applications are affected differently by manufacturing
variability.  For example, computational bound applications suffer more variability
compared to memory bound ones, since they stretch the cpu more.  An application using the
ALU unit may experience different levels of variability than another one using the FPU,
since they stretch different components of the processor (thus different transistors).
Any static approach, like statically distributing the parallel workload among processors
will be inefficient, since we cannot have a priori knowledge of how the variability on a
certain processor will affect a specific application.  Runtimes that employ dynamic
load-balancing on the other hand, can react to the effects of manufacturing variability
during execution. Although oblivious to the underlying heterogeneity of the system, a
runtime will redistribute work from busy to idle processors.  However, in this work we
show that even dynamic load-balancing can be further improved.  In Chapter
\ref{chap:power_aware_runtime} we present a runtime solution, which extends dynamic
load-balancing with dynamic resource redistribution in order to improve the performance of
parallel applications when running on power constrained NUMA nodes. We profile the
task-based PASRSECSs benchmarks under different power distributions among the sockets on
the same node and different number of active cores.  Our analysis shows that performance
can be improved up to 1.30x, when compared to evenly distributing power and having all
cores active.  We also extend the OpenMP 4.0 runtime system to transparently profile an
application during execution and then choose an optimized power and core distribution.
Our implementation starts off with an even distribution of power and cores among the
sockets and monitors the performance of tasks for small fraction of time.  It
consecutively tries and monitor different configurations to find a better candidate than
the starting configuration.  We also demonstrate that it is possible to achieve up to
1.22x speedup (optimal solution by static analysis is 1.3x speedup), by carefully
designing the configuration exploration space.  Eliminating configurations that are
unlikely to give good results, such as allocating more power to a socket with only a
couple of cores active.

\section{Model-driven Scheduling Mitigation of Manufacturing Variability}
Large HPC clusters are typically managed by dedicated software referred to as workload
managers.  This type of software manages user submitted workloads and allocates the
necessary resources, such as cores and memory.  Since these machines operate with hundreds
or thousands of cores, their power demands to operate are very high.  Moreover, current
HPC systems are power provisioned considering the worst case scenario, which is that all
nodes may need to operate at maximum capacity.  This scenario is not likely, as clusters
are typically running diverse type of applications.  Memory bound workloads stress the
processor less than computation bound ones, requiring less power while still making use of
the nodes they run on.  An emerging cluster design, which aims to make more efficient
power use and is known as overprovisioning, is to not abide by the aforementioned rule,
that the system must be provisioned with enough power to operate even at full capacity.
All nodes may be in use, but not at the upper limit of their power consumption.  If nodes
require more power, then less nodes should be used.

For a system such as this to operate, the workload manager must consider power as a finite
resource, as it does for cores and memory.  The workload manager should try to find
candidates that can run together without exceeding the power budget.  Current workload
managers do not implement this functionality, but possible solutions already exist in the
literature
\cite{patki:2013:eho:2464996.2465009,7515666,Inadomi:2015:AMI:2807591.2807638,Gholkar:2016:PTH:2967938.2967961,Ellsworth:2015:DPS:2807591.2807643,Bailey:2015:FLP:2807591.2807637,Teodorescu:2008:VAS:1381306.1382152,Totoni:tech:2014}.
However, most consider redistributing power where it is needed more, instead of
considering the power requirements of a workload at scheduling time.  Moreover, only a few
consider manufacturing variability.  In Section \ref{chap:power_aware_job_scheduling}, we
present an alternative approach, which indeed considers an application's power
requirements at scheduling time.  It decides which among multiple candidates should run
together, given a system-wide power budget which must not be exceeded.  Instead of relying
on user estimation, we employ an analytical model, which relies on PMC to predict an
application's power requirements.  We also extend the prediction model to consider
manufacturing variability.  Our evaluation against contemporary workload managers shows
that scheduling jobs, while considering their power requirements, can improve job
throughput up to 30\% or 24\%, for heavy and bursty traffic scenarios respectively.  In
terms of energy efficiency, we observe improvements up to 8\% and 4\% on average, for the
same heavy and bursty traffic scenarios.  When compared to manufacturing variability
agnostic approaches, our approach can alway guarantee that the power budget will not be
exceeded.  Contrary, scheduling policies that do not consider variability, may over- or
under-estimate power the consumption of an application.  This means that they either do
not manage to get optimal job throughput and energy efficiency or that the power budget
may be exceeded.  We also compare our variability-aware prediction model, to the current
state-of-the-art \cite{Inadomi:2015:AMI:2807591.2807638}, which relies on a single
benchmark to measure variability and then adjust the original variability-agnostic
prediction.  In contrast to our model, this approach relies on the unsound assumption that
all applications are impacted by manufacturing variability equally.  As already discussed,
this is not correct, a computation bound application will experience more variability than
a memory bound one, for example.  As a result, our prediction model is more reliable,
since it does not rely on the variability observed using a single benchmark.   
 
\section{Future Work}
The proposed methodologies and their evaluation results, presented in this thesis, lay the
foundations for further research topics.  These are the main research directions we
believe this research should head to:
\begin{itemize}
	\item Study impact of our runtime approach on emerging architectures:  Currently we
tested our methodology on a two socket machine.  A higher number of sockets on a single
NUMA node is possible and most likely newer systems will feature a higher number of NUMA
sockets on a single node.  Furthermore, vendors are enabling finer grain of control over
the individual cores, on newer generation of processors.  Currently, we were able to
enable/disable cores but not control each cores power consumption individually.  Instead,
the user can control and measure the power consumption of the sockets as a whole.
Broadwell and Haskwell family of processors already enable the user to control and monitor
the power of each core.  Our runtime approach could benefit from such fine control over
the processor, since it could identify the less power efficient cores, when choosing
candidates to disable, and achieve higher performance.  Moreover, A higher count of
sockets allows even more flexibility on how the power should be optimally distributed
among them.  However, it is of great interest to evaluate the benefits of this finer
control over the processors experimentally.  A challenge in for this line of research, is
to deal with the increased size of the exploration space, since higher count of cores and
sockets also means a higher number of configurations.  The exploration space needs to be
carefully designed, so that the additional cost of the runtime profiling does not result
in high overheads.
	\item Apply our proposed methodologies on emerging generations of processors:
Manufacturing variability is observed and expected to increase with newer generations of
processors \cite{Marathe:2017:ESP:3149412.3149421}.  The results of this thesis were
obtained on machines that experienced variability of 10\% for power and 20\% for
performance.  As this percentages increase so will the benefits of both our proposals.
Moreover, the variability agnostic approaches also presented in this thesis, for
comparison with our proposals, will perform even worse.  It is of interest to conduct a
thorough investigation and quantify the benefits of any variability-aware methodology, on
these newer processors.
	\item Predicting variability in performance.  Currently, our prediction models work very
well for predicting the power variability among sockets.  This information is essential
when trying to maintain the net power consumption of a system, below a certain budget.
However, alternative approaches achieve this by simply power constraining individual
components and sockets.  Although this may be effectively for not exceeding the power
budget, not considering the manufacturing variability will result in sub-optimal
scheduling of tasks (at runtime) and/or parallel workloads (at workload manager level).
Our runtime approach deals with this issue by monitoring an applications performance,
while trying different resource allocation on a NUMA node.  A workload manager typically
does not have such fine grain control or access over the individual application.  A
possible solution that could be adopted by a workload manager, would be to predict the
performance variability, thus identifying the heterogeneity of the system per application.
Predicting performance on power constrained processors is a challenging task, since all
performance counters are likely to be affected under different power consumption.  A
PMC-based model, such as the one presented in this thesis, would need to adapt to that
reality and researchers should find an approach that can deal with the varying monitoring
counter values.
\end{itemize}
\input{conclusions/appendix}

